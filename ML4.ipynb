{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CS3hDQqj7Pp",
        "outputId": "9bafb63c-a4d3-496a-b816-8db1626fba82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-25 23:50:44--  https://drive.google.com/u/0/uc?id=1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.210.138, 173.194.210.101, 173.194.210.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.210.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2&export=download [following]\n",
            "--2023-05-25 23:50:44--  https://drive.google.com/uc?id=1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/91il15c6o04npt1knp4vbch1cf24okfc/1685058600000/06789500609444976556/*/1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2?e=download&uuid=fb31d0eb-829d-4be4-8a26-98bed9927c41 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-05-25 23:50:44--  https://doc-10-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/91il15c6o04npt1knp4vbch1cf24okfc/1685058600000/06789500609444976556/*/1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2?e=download&uuid=fb31d0eb-829d-4be4-8a26-98bed9927c41\n",
            "Resolving doc-10-90-docs.googleusercontent.com (doc-10-90-docs.googleusercontent.com)... 108.177.13.132, 2607:f8b0:400c:c09::84\n",
            "Connecting to doc-10-90-docs.googleusercontent.com (doc-10-90-docs.googleusercontent.com)|108.177.13.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 626576 (612K) [text/csv]\n",
            "Saving to: ‘mumbai_houses_task.csv’\n",
            "\n",
            "mumbai_houses_task. 100%[===================>] 611.89K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2023-05-25 23:50:45 (125 MB/s) - ‘mumbai_houses_task.csv’ saved [626576/626576]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://drive.google.com/u/0/uc?id=1mpuQWoBEVsAYL7JIMvkAHkdaKtLOz_b2&export=download' -O mumbai_houses_task.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://drive.google.com/u/0/uc?id=1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f&export=download' -O csgo_task_update.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM5VgqpMy-K1",
        "outputId": "724f6c0f-d054-47b6-8fdf-9172e8c18d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-25 22:57:13--  https://drive.google.com/u/0/uc?id=1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f&export=download\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.12.102, 108.177.12.138, 108.177.12.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.12.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.google.com/uc?id=1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f&export=download [following]\n",
            "--2023-05-25 22:57:13--  https://drive.google.com/uc?id=1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f&export=download\n",
            "Reusing existing connection to drive.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-14-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mqs0hn4qktvlasn1u20qf04fp8me303u/1685055375000/06789500609444976556/*/1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f?e=download&uuid=87415503-f2dc-457b-b47d-aafd63c0bc5e [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-05-25 22:57:15--  https://doc-14-90-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mqs0hn4qktvlasn1u20qf04fp8me303u/1685055375000/06789500609444976556/*/1_cp9Z9Dm297VvfJB-cVlB_Z_L4sFZg4f?e=download&uuid=87415503-f2dc-457b-b47d-aafd63c0bc5e\n",
            "Resolving doc-14-90-docs.googleusercontent.com (doc-14-90-docs.googleusercontent.com)... 108.177.12.132, 2607:f8b0:400c:c08::84\n",
            "Connecting to doc-14-90-docs.googleusercontent.com (doc-14-90-docs.googleusercontent.com)|108.177.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10917260 (10M) [text/csv]\n",
            "Saving to: ‘csgo_task_update.csv’\n",
            "\n",
            "csgo_task_update.cs 100%[===================>]  10.41M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-05-25 22:57:15 (138 MB/s) - ‘csgo_task_update.csv’ saved [10917260/10917260]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# для оценки качества решения задачи регрессии\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# для оценки качества решения задачи классификации\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, RocCurveDisplay, auc, r2_score\n",
        "from sklearn.metrics import max_error\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "pHGiOhOkpHKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mumbai_houses_task.csv\")\n",
        "\n",
        "df['Status'] = df['Status'].fillna('Ready to Move')\n",
        "df['Furnished_status'] = df['Furnished_status'].fillna('Unfurnished')\n",
        "df = pd.get_dummies(df)\n",
        "print(pd.isnull(df).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oUkFB2QopO7",
        "outputId": "85108015-89d3-44d5-fb19-93dc0b4a41e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price                                0\n",
            "area                                 0\n",
            "latitude                             0\n",
            "longitude                            0\n",
            "Bedrooms                             0\n",
            "Bathrooms                            0\n",
            "Balcony                              0\n",
            "parking                              0\n",
            "Lift                                 0\n",
            "Status_Ready to Move                 0\n",
            "Status_Under Construction            0\n",
            "neworold_New Property                0\n",
            "neworold_Resale                      0\n",
            "Furnished_status_Furnished           0\n",
            "Furnished_status_Semi-Furnished      0\n",
            "Furnished_status_Unfurnished         0\n",
            "type_of_building_Flat                0\n",
            "type_of_building_Individual House    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"price\"]\n",
        "X = df.drop([\"price\"], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)\n",
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)\n",
        "\n",
        "X_train_reg = X_train\n",
        "X_test_reg = X_test\n",
        "y_train_reg = y_train\n",
        "y_test_reg = y_test\n",
        "\n",
        "y_cart = df[\"price\"].values\n",
        "X_cart = df.drop([\"price\"], axis=1).values\n",
        "X_train_cart, X_test_cart, y_train_cart, y_test_cart = train_test_split(X_cart, y_cart, test_size=1/3)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iQUzwMtrZgS",
        "outputId": "b9a0e582-d305-4532-e738-08dee91576e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4170, 17), (4170, 1), (2085, 17), (2085, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Regression"
      ],
      "metadata": {
        "id": "oC_w2wRU2l-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_regression = tf.keras.Sequential(\n",
        "    [\n",
        "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train_reg.shape[1],)),\n",
        "        # на втором скрытом слое будет 128 нейрона\n",
        "        tf.keras.layers.Dense(128, activation=\"linear\"),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # на выходе один нейрон, функция активации не применяется\n",
        "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
        "    ]\n",
        ")\n",
        "model_regression.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62RWWMZIuBmB",
        "outputId": "6ca88bfc-da8c-478f-c206-f0f8b9c634cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 64)                1152      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,353\n",
            "Trainable params: 20,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
      ],
      "metadata": {
        "id": "ofK6DXF6wWD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_regression.fit(X_train_reg, y_train_reg, epochs=50, verbose=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN_sn09BwY7f",
        "outputId": "601e7f69-1dc4-4df9-bf5b-547d0615d65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16a1fbb220>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# оцениваем качество с помощью метрик\n",
        "import numpy as np\n",
        "from random import random\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, classification_report, roc_curve, RocCurveDisplay, auc, r2_score\n",
        "\n",
        "print(mean_absolute_error(y_test_reg, model_regression.predict(X_test_reg)))\n",
        "print(mean_squared_error(y_test_reg, model_regression.predict(X_test_reg)))\n",
        "\n",
        "print(r2_score(y_test_reg,model_regression.predict(X_test_reg)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M9o5y7IUSv9",
        "outputId": "6215ee42-64ff-4f5b-e970-360930f77b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66/66 [==============================] - 0s 5ms/step\n",
            "11074545.909832135\n",
            "66/66 [==============================] - 0s 3ms/step\n",
            "392469979823284.5\n",
            "66/66 [==============================] - 0s 2ms/step\n",
            "0.4314188224972276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class"
      ],
      "metadata": {
        "id": "53MPVUkNtTjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"csgo_task_update.csv\", index_col=0).drop_duplicates()\n",
        "y = df['bomb_planted']\n",
        "X = df.drop(['bomb_planted'], axis=1)"
      ],
      "metadata": {
        "id": "UxrbBao6z6hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "iqvgtD_e9_z2",
        "outputId": "11db87d8-060c-4822-fd06-8e1bd3ae1f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        time_left  ct_score  t_score  bomb_planted  ct_health  t_health  \\\n",
              "0          175.00       0.0      0.0             0      500.0     500.0   \n",
              "1          156.03       0.0      0.0             0      500.0     500.0   \n",
              "2           96.03       0.0      0.0             0      391.0     400.0   \n",
              "3           76.03       0.0      0.0             0      391.0     400.0   \n",
              "4          174.97       1.0      0.0             0      500.0     500.0   \n",
              "...           ...       ...      ...           ...        ...       ...   \n",
              "122405      15.41      11.0     14.0             1      200.0     242.0   \n",
              "122406     174.93      11.0     15.0             0      500.0     500.0   \n",
              "122407     114.93      11.0     15.0             0      500.0     500.0   \n",
              "122408      94.93      11.0     15.0             0      500.0     500.0   \n",
              "122409      74.93      11.0     15.0             0      375.0     479.0   \n",
              "\n",
              "        ct_money  t_money  ct_players_alive  t_players_alive  map_de_cache  \\\n",
              "0         4000.0   4000.0               5.0              5.0             0   \n",
              "1          600.0    650.0               5.0              5.0             0   \n",
              "2          750.0    500.0               4.0              4.0             0   \n",
              "3          750.0    500.0               4.0              4.0             0   \n",
              "4        18350.0  10750.0               5.0              5.0             0   \n",
              "...          ...      ...               ...              ...           ...   \n",
              "122405     100.0   5950.0               2.0              4.0             0   \n",
              "122406   11500.0  23900.0               5.0              5.0             0   \n",
              "122407    1200.0   6700.0               5.0              5.0             0   \n",
              "122408    1200.0   6700.0               5.0              5.0             0   \n",
              "122409    1100.0   7000.0               4.0              5.0             0   \n",
              "\n",
              "        map_de_dust2  map_de_inferno  map_de_mirage  map_de_nuke  \\\n",
              "0                  1               0              0            0   \n",
              "1                  1               0              0            0   \n",
              "2                  1               0              0            0   \n",
              "3                  1               0              0            0   \n",
              "4                  1               0              0            0   \n",
              "...              ...             ...            ...          ...   \n",
              "122405             0               0              0            0   \n",
              "122406             0               0              0            0   \n",
              "122407             0               0              0            0   \n",
              "122408             0               0              0            0   \n",
              "122409             0               0              0            0   \n",
              "\n",
              "        map_de_overpass  map_de_train  map_de_vertigo  \n",
              "0                     0             0               0  \n",
              "1                     0             0               0  \n",
              "2                     0             0               0  \n",
              "3                     0             0               0  \n",
              "4                     0             0               0  \n",
              "...                 ...           ...             ...  \n",
              "122405                0             1               0  \n",
              "122406                0             1               0  \n",
              "122407                0             1               0  \n",
              "122408                0             1               0  \n",
              "122409                0             1               0  \n",
              "\n",
              "[116579 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aab4854-8304-437b-8cc1-0eddcd5b7937\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_left</th>\n",
              "      <th>ct_score</th>\n",
              "      <th>t_score</th>\n",
              "      <th>bomb_planted</th>\n",
              "      <th>ct_health</th>\n",
              "      <th>t_health</th>\n",
              "      <th>ct_money</th>\n",
              "      <th>t_money</th>\n",
              "      <th>ct_players_alive</th>\n",
              "      <th>t_players_alive</th>\n",
              "      <th>map_de_cache</th>\n",
              "      <th>map_de_dust2</th>\n",
              "      <th>map_de_inferno</th>\n",
              "      <th>map_de_mirage</th>\n",
              "      <th>map_de_nuke</th>\n",
              "      <th>map_de_overpass</th>\n",
              "      <th>map_de_train</th>\n",
              "      <th>map_de_vertigo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>175.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>96.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>174.97</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>18350.0</td>\n",
              "      <td>10750.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122405</th>\n",
              "      <td>15.41</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>200.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5950.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122406</th>\n",
              "      <td>174.93</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>11500.0</td>\n",
              "      <td>23900.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122407</th>\n",
              "      <td>114.93</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>6700.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122408</th>\n",
              "      <td>94.93</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>6700.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122409</th>\n",
              "      <td>74.93</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>479.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116579 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aab4854-8304-437b-8cc1-0eddcd5b7937')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aab4854-8304-437b-8cc1-0eddcd5b7937 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aab4854-8304-437b-8cc1-0eddcd5b7937');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "underSampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "X_under_sample, y_under_sample = underSampler.fit_resample(X, y)\n",
        "\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_under_sample, y_under_sample, test_size=0.2, random_state = 4)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train_clf, y_train_clf)\n",
        "X_train_std_clf = scaler.transform(X_train_clf)\n",
        "X_test_std_clf = scaler.transform(X_test_clf)"
      ],
      "metadata": {
        "id": "OitqbDUa8mfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_clf = df.drop([\"bomb_planted\"], axis=1).values\n",
        "y_clf = df[\"bomb_planted\"].values\n",
        "\n",
        "std = StandardScaler()\n",
        "std.fit(X_clf)\n",
        "X_clf = pd.DataFrame(std.transform(X_clf), columns=df.drop([\"bomb_planted\"], axis=1).columns).values\n",
        "\n",
        "underSampler = RandomUnderSampler(random_state=42)\n",
        "X_clf, y_clf = underSampler.fit_resample(X_clf,y_clf)\n",
        "X_clf= X_clf.reshape(X_clf.shape[0], 1, X_clf.shape[1])\n",
        "\n",
        "\n",
        "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, stratify=y_clf, test_size=0.2)"
      ],
      "metadata": {
        "id": "q6KE-Cqjz60h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1zJrHg20B9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Classification"
      ],
      "metadata": {
        "id": "uWw9Rs6u2eJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_classification_1 = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(X_train_clf.shape[1],)),\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.05),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        # сначала используем 1 нейрон и sigmoid\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "# в качестве функции активации используется бинарная  кроссэнтропия\n",
        "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
        "# verbose=None - не будет логов\n",
        "model_classification_1.fit(X_train_std_clf, y_train_clf, epochs=5, verbose=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFm1KWPu0fLk",
        "outputId": "b0ca78e4-184a-4b60-8526-3b2a3fa8ae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16a0d1cca0>"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_classification_1.predict(X_test_std_clf, verbose=None)[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo98eS5E0qIT",
        "outputId": "31e61f44-d8c3-44d8-98df-7e5b1b861939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.0150611e-22],\n",
              "       [1.6931263e-38],\n",
              "       [9.3717587e-01],\n",
              "       [3.3979455e-23],\n",
              "       [1.2518878e-20]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.around(model_classification_1.predict(X_test_std_clf, verbose=None))\n",
        "print(classification_report(y_test_clf, y_pred))\n",
        "print(confusion_matrix(y_test_clf, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtGxF5Zz04nl",
        "outputId": "bf5bb457-2786-45d5-88b6-2f95957822b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.90      0.94      2784\n",
            "           1       0.91      0.99      0.95      2690\n",
            "\n",
            "    accuracy                           0.95      5474\n",
            "   macro avg       0.95      0.95      0.95      5474\n",
            "weighted avg       0.95      0.95      0.95      5474\n",
            "\n",
            "[[2512  272]\n",
            " [  26 2664]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "решите задачи регрессии и классификации на ваших данных используя полносвязные нейронные сети; соберите их используя API Keras фреймворка TensorFlow; оцените качество полученных моделей с помощью метрик;"
      ],
      "metadata": {
        "id": "XRDcttaItwJO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPD4xGDVtxmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## многослойный персептрон\n",
        "с помощью которого можно решать задачи регрессии и классификации; предусмотрите возможность использовать такие функции активации, как sigmoid, tanh и relu; также предусмотрите возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой; реализуйте обучение персептрона методом обратного распространения ошибки; самостоятельно найдите производные функций sigmoid, tanh и relu; реализуйте классический градиентный спуск с возможностью указания шага"
      ],
      "metadata": {
        "id": "jl7QIyjU7pAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "554658918651225.0\n",
        "\n",
        "1359475019500038.2\n",
        "\n",
        "\n",
        "1383858462435473.2\n",
        "\n",
        "1559182145460672.8"
      ],
      "metadata": {
        "id": "sqXGMQy6XxNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sub2zhP0iCZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from subprocess import getoutput\n",
        "getoutput(\"git clone -l -s https://github.com/damianiRiccardo90/DL-Specialization DL-Specialization\")\n",
        "os.chdir(\"DL-Specialization/C1-Neural_Networks_and_Deep_Learning/W4-Deep_Neural_Networks\")\n",
        "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n"
      ],
      "metadata": {
        "id": "2zxpjETGZdG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters_deep(layer_dims):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
        "\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
        "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
        "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "\n",
        "    return parameters\n",
        "\n",
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "    Implement the linear part of a layer's forward propagation.\n",
        "\n",
        "    Arguments:\n",
        "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "\n",
        "    Returns:\n",
        "    Z -- the input of the activation function, also called pre-activation parameter\n",
        "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "\n",
        "    Z = np.dot(W, A) + b\n",
        "\n",
        "    cache = (A, W, b)\n",
        "\n",
        "    return Z, cache\n",
        "\n",
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    \"\"\"\n",
        "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
        "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
        "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "    Returns:\n",
        "    A -- the output of the activation function, also called the post-activation value\n",
        "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
        "             stored for computing the backward pass efficiently\n",
        "    \"\"\"\n",
        "\n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "\n",
        "    elif activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache\n",
        "\n",
        "def L_model_forward(X, parameters):\n",
        "    \"\"\"\n",
        "    AL -- last post-activation value\n",
        "    caches -- list of caches containing:\n",
        "    every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
        "    \"\"\"\n",
        "\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
        "    for l in range(1, L):\n",
        "        A_prev = A\n",
        "        A, cache = linear_activation_forward(\n",
        "            A_prev,\n",
        "            parameters['W' + str(l)],\n",
        "            parameters['b' + str(l)],\n",
        "            activation=\"relu\"\n",
        "        )\n",
        "        caches.append(cache)\n",
        "\n",
        "    AL, cache = linear_activation_forward(\n",
        "        A,\n",
        "        parameters['W' + str(L)],\n",
        "        parameters['b' + str(L)],\n",
        "        activation=\"sigmoid\"\n",
        "    )\n",
        "    caches.append(cache)\n",
        "\n",
        "    assert(AL.shape == (1,X.shape[1]))\n",
        "\n",
        "    return AL, caches\n",
        "\n",
        "\n",
        "def compute_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
        "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
        "    Returns:\n",
        "    cost -- cross-entropy cost\n",
        "    \"\"\"\n",
        "    m = Y.shape[1]\n",
        "\n",
        "    # Compute loss from aL and y.\n",
        "    cost = - np.sum(Y*np.log(AL) + (1-Y)*np.log(1-AL)) / m\n",
        "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    return cost\n",
        "\n",
        "\n",
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
        "\n",
        "    Arguments:\n",
        "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
        "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = np.dot(dZ, cache[0].T) / m\n",
        "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "    dA_prev = np.dot(cache[1].T, dZ)\n",
        "\n",
        "    assert (dA_prev.shape == A_prev.shape)\n",
        "    assert (dW.shape == W.shape)\n",
        "    assert (db.shape == b.shape)\n",
        "\n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient for current layer l\n",
        "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
        "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
        "\n",
        "    Returns:\n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "    \"\"\"\n",
        "    linear_cache, activation_cache = cache\n",
        "\n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "\n",
        "    return dA_prev, dW, db\n",
        "\n",
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ...\n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "\n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "\n",
        "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation=\"sigmoid\")\n",
        "\n",
        "    # Loop from l=L-2 to l=0\n",
        "    for l in reversed(range(L-1)):\n",
        "        # lth layer: (RELU -> LINEAR) gradients.\n",
        "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)]\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation=\"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads\n",
        "\n",
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "    parameters -- python dictionary containing your parameters\n",
        "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters\n",
        "                  parameters[\"W\" + str(l)] = ...\n",
        "                  parameters[\"b\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] -= learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] -= learning_rate * grads[\"db\" + str(l+1)]\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "NOlKGeC9Yxei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# perceptron"
      ],
      "metadata": {
        "id": "fClvmyYJICbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation:\n",
        "    def Function(x):\n",
        "        pass\n",
        "    def Derivative(x):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Sigmoid(Activation):\n",
        "    @staticmethod\n",
        "    def Function(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    @staticmethod\n",
        "    def Derivative(x):\n",
        "        return Sigmoid.Function(x) * (1- Sigmoid.Function(x))\n",
        "\n",
        "class TangH(Activation):\n",
        "    @staticmethod\n",
        "    def Function( x):\n",
        "        return (np.exp(x) - np.exp(-x)) / (np.exp(x)+np.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def Derivative(x):\n",
        "        return 1 - TangH.Function(x) ** 2\n",
        "\n",
        "class Relu(Activation):\n",
        "    @staticmethod\n",
        "    def Function(x):\n",
        "        return np.maximum(0,x)\n",
        "    @staticmethod\n",
        "    def Derivative(x):\n",
        "        return np.where(x > 0, 1.0, 0.0)\n",
        "\n",
        "\n",
        "\n",
        "class LossFunction:\n",
        "    def fun():\n",
        "        pass\n",
        "    def derivative():\n",
        "        pass\n",
        "\n",
        "class MeanSquaredError(LossFunction):\n",
        "    def fun(y_true, y_pred):\n",
        "        return np.mean(np.power(y_true-y_pred, 2))\n",
        "\n",
        "    def derivative(y_true, y_pred):\n",
        "        return 2*(y_pred-y_true)/y_true.size"
      ],
      "metadata": {
        "id": "tzs56JFFsqnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward_propagation(self, input):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward_propagation(self, output_error):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class FCLayer(Layer):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "        self.bias = np.random.rand(1, output_size) - 0.5\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = np.dot(self.input, self.weights) + self.bias\n",
        "        return self.output\n",
        "\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        input_error = np.dot(output_error, self.weights.T)#dE/dx\n",
        "        weights_error = np.dot(self.input.T, output_error)#dE/dw\n",
        "        self.weights -= learning_rate * weights_error\n",
        "        self.bias -= learning_rate * output_error\n",
        "        return input_error #de/db = de/dx\n",
        "\n",
        "class ActivationLayer(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward_propagation(self, input_data):\n",
        "        self.input = input_data\n",
        "        self.output = self.activation(self.input)\n",
        "        return self.output\n",
        "\n",
        "    def backward_propagation(self, output_error, learning_rate):\n",
        "        return self.activation_prime(self.input) * output_error\n",
        "\n",
        "class NN:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.loss_prime = None\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def use(self, loss, loss_prime):\n",
        "        self.loss = loss\n",
        "        self.loss_prime = loss_prime\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        samples = len(input_data)\n",
        "        result = []\n",
        "\n",
        "        for i in range(samples):\n",
        "            output = input_data[i]\n",
        "            for layer in self.layers:\n",
        "                output = layer.forward_propagation(output)\n",
        "            result.append(*output)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def fit(self, x_train, y_train, epochs, learning_rate, verbose = True):\n",
        "        samples = len(x_train)\n",
        "\n",
        "        # train\n",
        "        for i in range(epochs):\n",
        "            err = 0\n",
        "            for j in range(samples):\n",
        "                # forward propagation\n",
        "                output = x_train[j]\n",
        "                for layer in self.layers:\n",
        "                    output = layer.forward_propagation(output)\n",
        "\n",
        "\n",
        "                err += self.loss(y_train[j], output)\n",
        "\n",
        "                # backward propagation\n",
        "                error = self.loss_prime(y_train[j], output)\n",
        "                for layer in reversed(self.layers):\n",
        "                    error = layer.backward_propagation(error, learning_rate)\n",
        "\n",
        "            err /= samples\n",
        "            if(verbose):\n",
        "                print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
      ],
      "metadata": {
        "id": "TnG7h0gCpMxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class"
      ],
      "metadata": {
        "id": "-ybwdxjTIEY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_classification = NN()\n",
        "model_classification.add(FCLayer(17, 8))\n",
        "model_classification.add(ActivationLayer(TangH.Function, TangH.Derivative))\n",
        "model_classification.add(FCLayer(8, 1))\n",
        "model_classification.add(ActivationLayer(Sigmoid.Function, Sigmoid.Derivative))\n",
        "\n",
        "model_classification.use(MeanSquaredError.fun, MeanSquaredError.derivative)\n",
        "\n",
        "model_classification.fit(X_clf_train, y_clf_train, epochs=5, learning_rate=0.001)\n",
        "pred_classification = model_classification.predict(X_clf_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OAcmzinxgKI",
        "outputId": "64f704b6-107c-45df-b99c-eb140f840427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/5   error=0.123118\n",
            "epoch 2/5   error=0.088383\n",
            "epoch 3/5   error=0.078358\n",
            "epoch 4/5   error=0.069741\n",
            "epoch 5/5   error=0.063700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.around(pred_classification)\n",
        "\n",
        "print(r2_score(y_clf_test,pred_classification))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1eEKC1Z2qvx",
        "outputId": "fa674d76-b72f-4ee7-d61c-bb63183a55ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7292065598888271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_clf_test, np.around(pred_classification)))\n",
        "print(confusion_matrix(y_clf_test, np.around(pred_classification)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCWPTqld2Oh0",
        "outputId": "510ab519-21a0-4c40-fc22-ece54918bd22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.87      0.91      2737\n",
            "           1       0.88      0.96      0.92      2737\n",
            "\n",
            "    accuracy                           0.91      5474\n",
            "   macro avg       0.92      0.91      0.91      5474\n",
            "weighted avg       0.92      0.91      0.91      5474\n",
            "\n",
            "[[2371  366]\n",
            " [ 105 2632]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reg = pd.read_csv(\"mumbai_houses_task.csv\")\n",
        "\n",
        "df_reg['Status'] = df_reg['Status'].fillna('Ready to Move')\n",
        "df_reg['Furnished_status'] = df_reg['Furnished_status'].fillna('Unfurnished')\n",
        "df_reg = pd.get_dummies(df_reg)"
      ],
      "metadata": {
        "id": "TdLTYuyTF5-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_reg = df[\"price\"].values\n",
        "X_reg = df.drop([\"price\"], axis=1).values.reshape(df_reg.shape[0], 1, df_reg.shape[1] - 1)"
      ],
      "metadata": {
        "id": "bS_LAoJrGfuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2,random_state=4)\n",
        "X_train_reg.shape, X_test_reg.shape, y_train_reg.shape, y_test_reg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoL9SqZ5G4bz",
        "outputId": "0690c67a-b87e-4bd5-c460-b2e701b82c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5004, 1, 17), (1251, 1, 17), (5004,), (1251,))"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reg"
      ],
      "metadata": {
        "id": "JRihugt-IM3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_classification = NN()\n",
        "model_classification.add(FCLayer(X_train_reg.shape[2], 8))\n",
        "model_classification.add(ActivationLayer(Relu.Function, Relu.Derivative))\n",
        "model_classification.add(FCLayer(8, 1))\n",
        "model_classification.add(ActivationLayer(Relu.Function, Relu.Derivative))\n",
        "\n",
        "model_classification.use(MeanSquaredError.fun, MeanSquaredError.derivative)\n",
        "\n",
        "model_classification.fit(X_train_reg, y_train_reg, epochs=5, learning_rate=0.0000001)\n",
        "pred_classification = model_classification.predict(X_test_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIIuVQL3xGw4",
        "outputId": "f6a63961-3b33-4994-8722-56eca4a044c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/5   error=1502915533093523.750000\n",
            "epoch 2/5   error=1502915533093523.750000\n",
            "epoch 3/5   error=1502915533093523.750000\n",
            "epoch 4/5   error=1502915533093523.750000\n",
            "epoch 5/5   error=1502915533093523.750000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_absolute_error(y_test_reg,pred_classification))\n",
        "print(mean_squared_error(y_test_reg,pred_classification))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-oGbHAAHW37",
        "outputId": "bde4b4b6-8919-497a-eadf-809b91fe4183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26743485.211830534\n",
            "1478936449240607.5\n"
          ]
        }
      ]
    }
  ]
}